{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Masar Occupancy â€” Month Generator**\n",
        "\n",
        "Generates **minute-level passenger occupancy** for a full **calendar month** across selected stations/lines.  \n",
        "Starts from a **base-day curve** and applies **context modifiers** (station capacity, weekend, weather, and events; holidays configurable),  \n",
        "then exports tidy CSVs for dashboards and Firestore/pipeline publishing.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Purpose\n",
        "- Produce **month-long time series** at **1-minute resolution**.\n",
        "- Robustly fill all calendar days and keep station/event consistency.\n",
        "- Output **validated CSVs**: per-day (optional) and a **consolidated monthly file**.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§© Inputs\n",
        "`base_day.csv` (or `day_base.csv`), Seeds: `stations`, `events`, `holidays` (optional), `weather`, Config: `00_config.yaml`.\n",
        "\n",
        "---\n",
        "\n",
        "### âš™ï¸ Workflow\n",
        "1) Load config & seeds.  \n",
        "2) Select month window (e.g., `2025-09`).  \n",
        "3) Build minute grid per day & station.  \n",
        "4) Compute modifiers (weekend, weather, events, holiday toggle).  \n",
        "5) Map to `station_total` by capacity; derive `crowd_level`.  \n",
        "6) QA & export consolidated monthly CSV (and optional per-day files).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "i4rGZm26JcVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/Jana-Alrzoog/2025_GP_28.git\n",
        "%cd /content/2025_GP_28/masar-sim\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwrEB5u32MD6",
        "outputId": "94791b5f-37f1-420e-900f-e0cd58f6c594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '2025_GP_28'...\n",
            "remote: Enumerating objects: 716, done.\u001b[K\n",
            "remote: Counting objects: 100% (231/231), done.\u001b[K\n",
            "remote: Compressing objects: 100% (224/224), done.\u001b[K\n",
            "remote: Total 716 (delta 120), reused 1 (delta 1), pack-reused 485 (from 1)\u001b[K\n",
            "Receiving objects: 100% (716/716), 8.11 MiB | 7.84 MiB/s, done.\n",
            "Resolving deltas: 100% (267/267), done.\n",
            "/content/2025_GP_28/masar-sim\n",
            "data  lib  notebooks  sims\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB-p9pLs101k",
        "outputId": "4e0ad7d0-0dfb-45cc-8cd8-3b5311a42d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROOT = /content/2025_GP_28/masar-sim\n",
            "GEN  = /content/2025_GP_28/masar-sim/data/generated\n",
            "CONF = /content/2025_GP_28/masar-sim/sims/00_config.yaml\n",
            "base_day rows=6,486, stations=6, day=2025-09-24\n"
          ]
        }
      ],
      "source": [
        "# Generate a full month with changing scenarios\n",
        "\n",
        "import os, json, csv, yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil.parser import parse\n",
        "\n",
        "CANDIDATES = [\n",
        "    \"/content/2025_GP_28_latest/masar-sim\",\n",
        "    \"/content/2025_GP_28/masar-sim\",\n",
        "    \"/content/masar-sim\",\n",
        "]\n",
        "ROOT = next((p for p in CANDIDATES if os.path.exists(p)), None)\n",
        "assert ROOT, \"Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¬Ù„Ø¯ masar-sim. ØªØ£ÙƒØ¯ÙŠ Ù…Ù† Ø§Ù„ÙƒÙ„ÙˆÙ† ÙˆØ§Ù„Ù…Ø³Ø§Ø±.\"\n",
        "SEED = f\"{ROOT}/data/seeds\"\n",
        "GEN  = f\"{ROOT}/data/generated\"\n",
        "CONF = f\"{ROOT}/sims/00_config.yaml\"\n",
        "\n",
        "print(\"ROOT =\", ROOT)\n",
        "print(\"GEN  =\", GEN)\n",
        "print(\"CONF =\", CONF)\n",
        "\n",
        "with open(CONF) as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "with open(f\"{SEED}/stations.json\") as f:\n",
        "    stations = json.load(f)\n",
        "with open(f\"{SEED}/weather_patterns.json\") as f:\n",
        "    weather_map = json.load(f)\n",
        "with open(f\"{SEED}/calendar_events.csv\") as f:\n",
        "    events_seed = list(csv.DictReader(f))\n",
        "\n",
        "\n",
        "base_path = f\"{GEN}/base_day.csv\"\n",
        "assert os.path.exists(base_path), \"base_day.csv ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯â€”Ø´ØºÙ‘Ù„ÙŠ masar_base_demand.ipynb Ø£ÙˆÙ„Ù‹Ø§.\"\n",
        "base_day = pd.read_csv(base_path, parse_dates=[\"timestamp\"])\n",
        "print(f\"base_day rows={len(base_day):,}, stations={base_day['station_id'].nunique()}, day={base_day['timestamp'].dt.date.iloc[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masar Occupancy â€” Month Generator (September 2025)\n",
        "# - Builds minute-level demand for 2025-09-01 â†’ 2025-09-30\n",
        "# - Event types are read from calendar_events.csv per date/station\n",
        "# - Holidays can be toggled (default OFF)\n",
        "# - Saves consolidated monthly CSV (+ optional per-day files)\n",
        "\n",
        "import os, csv, json, yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Paths & config\n",
        "ROOT = \"/content/2025_GP_28/masar-sim\"\n",
        "SEED = f\"{ROOT}/data/seeds\"\n",
        "CONF = f\"{ROOT}/sims/00_config.yaml\"\n",
        "OUT_DIR = f\"{ROOT}/data/generated\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "with open(CONF, \"r\", encoding=\"utf-8\") as f:\n",
        "    config = yaml.safe_load(f) or {}\n",
        "\n",
        "# Month window (inclusive)\n",
        "MONTH = \"2025-09\"\n",
        "MONTH_START = pd.Timestamp(f\"{MONTH}-01\")\n",
        "MONTH_END   = pd.Timestamp(f\"{MONTH}-30\")  # 30 days in Sep 2025\n",
        "\n",
        "HOLIDAYS_ON = False         # set True to enable holiday multipliers\n",
        "SAVE_DAILY  = False         # set True if you also want per-day CSVs\n",
        "\n",
        "# 1- Load base-day template\n",
        "# We only need a single-day base grid: station_id, minute_of_day, base_demand\n",
        "candidates = [\n",
        "    f\"{OUT_DIR}/day_base.csv\",\n",
        "    f\"{OUT_DIR}/base_day.csv\",\n",
        "    f\"{ROOT}/data/base/day_base.csv\",\n",
        "    f\"{ROOT}/data/base/base_day.csv\",\n",
        "    f\"{OUT_DIR}/day_demand_base.csv\",\n",
        "    f\"{ROOT}/data/base/day_demand_base.csv\",\n",
        "]\n",
        "src = next((p for p in candidates if os.path.exists(p)), None)\n",
        "if src is None:\n",
        "    raise FileNotFoundError(\"No base-day CSV found. Expected one of:\\n\" + \"\\n\".join(candidates))\n",
        "base_day = pd.read_csv(src)\n",
        "print(\"Loaded base-day from:\", src)\n",
        "\n",
        "# Normalize headers\n",
        "base_day.columns = [str(c).strip().lower() for c in base_day.columns]\n",
        "rename_map = {\n",
        "    \"station\":\"station_id\",\"station code\":\"station_id\",\"station_code\":\"station_id\",\"sid\":\"station_id\",\n",
        "    \"base\":\"base_demand\",\"basedemand\":\"base_demand\",\"demand_base\":\"base_demand\",\n",
        "    \"base_day_demand\":\"base_demand\",\"base_day\":\"base_demand\",\n",
        "    \"minute\":\"minute_of_day\",\"min\":\"minute_of_day\",\"minuteofday\":\"minute_of_day\",\"minute-of-day\":\"minute_of_day\",\n",
        "}\n",
        "base_day = base_day.rename(columns=rename_map)\n",
        "\n",
        "# Build minute_of_day if missing\n",
        "if \"minute_of_day\" not in base_day.columns:\n",
        "    if {\"hour\",\"minute\"}.issubset(base_day.columns):\n",
        "        base_day[\"minute_of_day\"] = (pd.to_numeric(base_day[\"hour\"], errors=\"coerce\").fillna(0).astype(int)*60 +\n",
        "                                     pd.to_numeric(base_day[\"minute\"], errors=\"coerce\").fillna(0).astype(int))\n",
        "    elif \"time\" in base_day.columns:\n",
        "        t = pd.to_datetime(base_day[\"time\"], errors=\"coerce\")\n",
        "        base_day[\"minute_of_day\"] = (t.dt.hour*60 + t.dt.minute).astype(\"Int64\").fillna(0).astype(int)\n",
        "    elif \"timestamp\" in base_day.columns:\n",
        "        ts = pd.to_datetime(base_day[\"timestamp\"], errors=\"coerce\")\n",
        "        base_day[\"minute_of_day\"] = (ts.dt.hour*60 + ts.dt.minute).astype(\"Int64\").fillna(0).astype(int)\n",
        "    else:\n",
        "        # best-effort fallback, if rows are minute-ordered\n",
        "        base_day = base_day.reset_index().rename(columns={\"index\":\"minute_of_day\"})\n",
        "        base_day[\"minute_of_day\"] = base_day[\"minute_of_day\"].clip(0, 1439).astype(int)\n",
        "for c in [\"station_id\",\"base_demand\"]:\n",
        "    if c not in base_day.columns:\n",
        "        raise KeyError(f\"Missing required column '{c}' in base-day template.\")\n",
        "base_day[\"station_id\"]  = base_day[\"station_id\"].astype(str).str.strip()\n",
        "base_day[\"base_demand\"] = pd.to_numeric(base_day[\"base_demand\"], errors=\"coerce\").fillna(0.0)\n",
        "base_day[\"minute_of_day\"] = pd.to_numeric(base_day[\"minute_of_day\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# 2- Stations & capacities\n",
        "def _norm(x): return str(x).strip().upper()\n",
        "with open(f\"{SEED}/stations.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    stations_list = json.load(f)\n",
        "capacity_df = pd.DataFrame(stations_list)[[\"station_id\",\"capacity_station\"]]\n",
        "sid_by_code, sid_by_name = {}, {}\n",
        "for st in stations_list:\n",
        "    sid  = str(st.get(\"station_id\",\"\")).strip()\n",
        "    code = str(st.get(\"code\",\"\")).strip()\n",
        "    name = str(st.get(\"name\",\"\")).strip()\n",
        "    if code: sid_by_code[_norm(code)] = sid\n",
        "    if name: sid_by_name[_norm(name)] = sid\n",
        "\n",
        "ALIASES = {\n",
        "    \"AIRPORT T1-2\": \"AIRP_T12\",\n",
        "    \"QASR AL-HOKM\": \"QASR\",\n",
        "    \"NATIONAL MUSEUM\": \"MUSEUM\",\n",
        "    \"WESTERN STATION\": \"S6\",\n",
        "}\n",
        "def resolve_sid(token: str):\n",
        "    t = _norm(token)\n",
        "    if t in sid_by_code: return sid_by_code[t]\n",
        "    if t in sid_by_name: return sid_by_name[t]\n",
        "    if t in ALIASES:\n",
        "        c = _norm(ALIASES[t]); return sid_by_code.get(c, ALIASES[t])\n",
        "    return None\n",
        "\n",
        "# 3- Calendar (events & holidays)\n",
        "def norm_date(x: str) -> str:\n",
        "    if x is None: return \"\"\n",
        "    s = str(x).strip()\n",
        "    if not s: return \"\"\n",
        "    d = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
        "    if pd.isna(d):\n",
        "        d = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
        "    return \"\" if pd.isna(d) else d.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Events\n",
        "events_csv = f\"{SEED}/calendar_events.csv\"\n",
        "event_rows = []\n",
        "with open(events_csv, \"r\", encoding=\"utf-8\") as f:\n",
        "    rdr = csv.DictReader(f)\n",
        "    cols = {c.lower().strip(): c for c in rdr.fieldnames}\n",
        "    for r in rdr:\n",
        "        event_rows.append({\n",
        "            \"date\": norm_date(r.get(cols.get(\"date\",\"date\"), \"\")),\n",
        "            \"event_type\": (r.get(cols.get(\"event_type\",\"event_type\")) or r.get(cols.get(\"type\",\"type\")) or \"Other\").strip(),\n",
        "            \"stations_impacted\": (r.get(cols.get(\"stations_impacted\",\"stations_impacted\")) or r.get(cols.get(\"stations\",\"stations\")) or \"*\").strip(),\n",
        "            \"demand_modifier\": float((r.get(cols.get(\"demand_modifier\",\"demand_modifier\")) or \"1.0\")),\n",
        "        })\n",
        "\n",
        "GLOBAL_EVENT_TYPES = {\"SaudiNationalDay\"}\n",
        "event_types_map = {}              # (date, SID) -> set(types)\n",
        "event_mult_override = {}          # (date, SID) -> product(mods)\n",
        "global_event_types_by_date = {}   # date -> set(types)\n",
        "global_event_mult_by_date  = {}   # date -> product(mods)\n",
        "\n",
        "for e in event_rows:\n",
        "    d = e[\"date\"]\n",
        "    if not d: continue\n",
        "    etype = e[\"event_type\"] or \"Other\"\n",
        "    dm    = float(e.get(\"demand_modifier\", 1.0) or 1.0)\n",
        "    tokens = [s.strip() for s in (e[\"stations_impacted\"] or \"*\").split(\";\")]\n",
        "\n",
        "    is_global = (etype in GLOBAL_EVENT_TYPES) or any(_norm(t) in {\"*\",\"ALL\",\"ALL STATIONS\"} for t in tokens)\n",
        "    if is_global:\n",
        "        global_event_types_by_date.setdefault(d, set()).add(etype)\n",
        "        global_event_mult_by_date[d] = global_event_mult_by_date.get(d, 1.0) * dm\n",
        "\n",
        "    for tok in tokens:\n",
        "        if tok == \"\" or _norm(tok) in {\"*\",\"ALL\",\"ALL STATIONS\"}: continue\n",
        "        sid = resolve_sid(tok)\n",
        "        if sid is None:\n",
        "            print(f\"[warn] Unknown station alias in events CSV: '{tok}'\")\n",
        "            continue\n",
        "        key = (d, _norm(sid))\n",
        "        event_types_map.setdefault(key, set()).add(etype)\n",
        "        event_mult_override[key] = event_mult_override.get(key, 1.0) * dm\n",
        "\n",
        "# Holidays\n",
        "holiday_dates = set()\n",
        "if HOLIDAYS_ON:\n",
        "    holidays_csv = f\"{SEED}/holidays.csv\"\n",
        "    if os.path.exists(holidays_csv):\n",
        "        with open(holidays_csv, \"r\", encoding=\"utf-8\") as f:\n",
        "            rdr = csv.DictReader(f)\n",
        "            cols = {c.lower().strip(): c for c in rdr.fieldnames}\n",
        "            for r in rdr:\n",
        "                d = norm_date(r.get(cols.get(\"date\",\"date\"), \"\"))\n",
        "                if d: holiday_dates.add(d)\n",
        "\n",
        "def list_event_types(date_str, sid):\n",
        "    sidn = _norm(sid)\n",
        "    types = set()\n",
        "    if (date_str, sidn) in event_types_map:\n",
        "        types |= event_types_map[(date_str, sidn)]\n",
        "    if date_str in global_event_types_by_date:\n",
        "        types |= global_event_types_by_date[date_str]\n",
        "    return sorted(types)\n",
        "\n",
        "def event_csv_multiplier(date_str, sid):\n",
        "    sidn = _norm(sid)\n",
        "    m = 1.0\n",
        "    if (date_str, sidn) in event_mult_override:\n",
        "        m *= event_mult_override[(date_str, sidn)]\n",
        "    if date_str in global_event_mult_by_date:\n",
        "        m *= global_event_mult_by_date[date_str]\n",
        "    return float(m)\n",
        "\n",
        "#4- Multipliers\n",
        "mult_cfg     = (config.get(\"multipliers\", {}) or {})\n",
        "weather_mult = mult_cfg.get(\"weather\", {}) or {}\n",
        "events_mult  = mult_cfg.get(\"events\", {}) or {}\n",
        "weekend_mult = float(mult_cfg.get(\"weekend\", 1.0))\n",
        "holiday_mult = float(mult_cfg.get(\"holiday\", 1.0)) if HOLIDAYS_ON else 1.0\n",
        "COMBINE_MODE = \"stack\"  # multiply components\n",
        "\n",
        "def build_modifier(row):\n",
        "    m = 1.0\n",
        "    # weekend\n",
        "    if int(row.get(\"is_weekend\",0)) == 1:\n",
        "        m *= weekend_mult\n",
        "\n",
        "    # holiday\n",
        "    hol_m = holiday_mult if row[\"date\"] in holiday_dates else 1.0\n",
        "\n",
        "    # events\n",
        "    ev_m = event_csv_multiplier(row[\"date\"], row[\"station_id\"])\n",
        "    if ev_m == 1.0:\n",
        "        tmp = 1.0\n",
        "        for t in list_event_types(row[\"date\"], row[\"station_id\"]):\n",
        "            tmp *= float(events_mult.get(t, events_mult.get(\"Other\", 1.0)))\n",
        "        ev_m = tmp if tmp != 1.0 else 1.0\n",
        "\n",
        "    m = m * hol_m * ev_m if COMBINE_MODE == \"stack\" else m * max(hol_m, ev_m)\n",
        "\n",
        "    # weather\n",
        "    w = str(row.get(\"weather_code\", \"\") or \"\")\n",
        "    m *= float(weather_mult.get(w, 1.0))\n",
        "    return float(m)\n",
        "\n",
        "# 5- Build the full month grid\n",
        "dates = pd.date_range(MONTH_START, MONTH_END, freq=\"D\")\n",
        "frames = []\n",
        "for d in dates:\n",
        "    df_d = base_day.copy()\n",
        "    h = (df_d[\"minute_of_day\"] // 60).astype(int)\n",
        "    m = (df_d[\"minute_of_day\"] %  60).astype(int)\n",
        "    date_iso = d.strftime(\"%Y-%m-%d\")\n",
        "    df_d[\"date\"]        = date_iso\n",
        "    df_d[\"timestamp\"]   = pd.to_datetime(f\"{date_iso} \" + h.astype(str).str.zfill(2) + \":\" + m.astype(str).str.zfill(2) + \":00\")\n",
        "    df_d[\"hour\"]        = h\n",
        "    df_d[\"day_of_week\"] = d.weekday()\n",
        "    df_d[\"is_weekend\"]  = df_d[\"day_of_week\"].isin([4,5]).astype(int)  # Fri=4, Sat=5\n",
        "    frames.append(df_d)\n",
        "\n",
        "df = pd.concat(frames, ignore_index=True).sort_values([\"date\",\"station_id\",\"minute_of_day\"]).reset_index(drop=True)\n",
        "\n",
        "# 6- Apply modifiers & map to capacity\n",
        "df[\"modifier\"] = df.apply(build_modifier, axis=1)\n",
        "base_demand_safe = pd.to_numeric(df.get(\"base_demand\", 0), errors=\"coerce\").fillna(0)\n",
        "df[\"demand_final\"] = (base_demand_safe * pd.to_numeric(df[\"modifier\"], errors=\"coerce\").fillna(1.0)).fillna(0)\n",
        "\n",
        "# capacities\n",
        "df = df.merge(capacity_df, on=\"station_id\", how=\"left\")\n",
        "\n",
        "# normalize by GLOBAL monthly max (for realistic network-wide scaling)\n",
        "global_max = max(df[\"demand_final\"].max(), 1e-9)\n",
        "df[\"_denom\"] = global_max\n",
        "df[\"demand_norm_final\"] = (df[\"demand_final\"] / df[\"_denom\"]).clip(0, 1)\n",
        "\n",
        "def station_total_from_norm(row):\n",
        "    cap = float(row.get(\"capacity_station\") or 0)\n",
        "    if cap <= 0: return 0\n",
        "    norm = float(row[\"demand_norm_final\"])\n",
        "    evb  = event_csv_multiplier(row[\"date\"], row[\"station_id\"])\n",
        "    boost = min(1.10, 1.0 if evb <= 1.0 else min(evb, 1.10))  # +10% on event boost\n",
        "    return int(np.round(norm * cap * boost))\n",
        "\n",
        "df[\"station_total\"] = df.apply(station_total_from_norm, axis=1).astype(int)\n",
        "\n",
        "def crowd_from_cap(row):\n",
        "    cap = float(row.get(\"capacity_station\") or 0)\n",
        "    x = float(row.get(\"station_total\") or 0)\n",
        "    if cap <= 0: return \"Medium\"\n",
        "    r = x / cap\n",
        "    if   r < 0.30: return \"Low\"\n",
        "    elif r < 0.60: return \"Medium\"\n",
        "    elif r < 0.85: return \"High\"\n",
        "    else:          return \"Extreme\"\n",
        "df[\"crowd_level\"] = df.apply(crowd_from_cap, axis=1)\n",
        "\n",
        "# flags / types, will read from calendar CSV\n",
        "df[\"special_event_type\"] = df.apply(lambda r: \"+\".join(list_event_types(r[\"date\"], r[\"station_id\"])) or \"None\", axis=1)\n",
        "df[\"event_flag\"]   = (df[\"special_event_type\"] != \"None\").astype(int)\n",
        "df[\"holiday_flag\"] = df[\"date\"].isin(holiday_dates).astype(int) if HOLIDAYS_ON else 0\n",
        "\n",
        "# headways\n",
        "headway_cfg = config.get(\"headway\", {})\n",
        "peaks_cfg   = config.get(\"peaks\", [])\n",
        "peak_hours  = [int(x.get(\"hour\")) for x in peaks_cfg if \"hour\" in x]\n",
        "peak_hw_min    = float(np.median(headway_cfg.get(\"peak_pattern\",    [7,7,6,8])))\n",
        "offpeak_hw_min = float(np.median(headway_cfg.get(\"offpeak_pattern\", [11,10,12,11])))\n",
        "def hw_for_hour(h): return int(peak_hw_min*60) if int(h) in peak_hours else int(offpeak_hw_min*60)\n",
        "df[\"headway_seconds\"] = df.get(\"headway_seconds\")\n",
        "df[\"headway_seconds\"] = pd.to_numeric(df[\"headway_seconds\"], errors=\"coerce\")\n",
        "mask = df[\"headway_seconds\"].isna()\n",
        "df.loc[mask, \"headway_seconds\"] = df.loc[mask, \"hour\"].apply(hw_for_hour)\n",
        "df[\"headway_seconds\"] = df[\"headway_seconds\"].astype(int)\n",
        "\n",
        "# 7- Output (monthly + optional daily)\n",
        "FINAL_SCHEMA = [\n",
        "    \"date\",\"timestamp\",\"hour\",\"minute_of_day\",\"day_of_week\",\"is_weekend\",\n",
        "    \"station_id\",\n",
        "    \"base_demand\",\"modifier\",\"demand_final\",\n",
        "    \"station_total\",\"crowd_level\",\n",
        "    \"special_event_type\",\"event_flag\",\"holiday_flag\",\n",
        "    \"headway_seconds\"\n",
        "]\n",
        "for c in FINAL_SCHEMA:\n",
        "    if c not in df.columns:\n",
        "        df[c] = np.nan\n",
        "out = df[FINAL_SCHEMA].sort_values([\"date\",\"station_id\",\"minute_of_day\"]).reset_index(drop=True)\n",
        "\n",
        "# QA\n",
        "assert out[\"station_id\"].notna().all()\n",
        "assert (out[\"station_total\"] >= 0).all()\n",
        "\n",
        "# Save monthly file\n",
        "OUT_MONTH = f\"{OUT_DIR}/cf_month_{MONTH}.csv\"\n",
        "out.to_csv(OUT_MONTH, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"Saved âœ“\", OUT_MONTH, \"| Rows:\", len(out), \"| Dates:\", out['date'].min(), \"â†’\", out['date'].max())\n",
        "\n",
        "# here is Optional, per-day files\n",
        "if SAVE_DAILY:\n",
        "    for d, g in out.groupby(\"date\", sort=True):\n",
        "        p = f\"{OUT_DIR}/cf_day_{d}.csv\"\n",
        "        g.to_csv(p, index=False, encoding=\"utf-8-sig\")\n",
        "    print(\"Daily CSVs saved in:\", OUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3MN-R6jKRH0",
        "outputId": "9dd05448-3eba-453b-e41d-26d921a94bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded base-day from: /content/2025_GP_28/masar-sim/data/generated/base_day.csv\n",
            "Saved âœ“ /content/2025_GP_28/masar-sim/data/generated/cf_month_2025-09.csv | Rows: 194580 | Dates: 2025-09-01 â†’ 2025-09-30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masar Occupancy â€” Month Generator (September 2025)\n",
        "# - Builds minute-level demand for 2025-09-01 â†’ 2025-09-30\n",
        "# - Reads event types from calendar_events.csv per date/station\n",
        "# - Converts normalized base-day demand into pax/min using\n",
        "#   service capacity (headway, train capacity, directions)\n",
        "# - Computes minute-level station occupancy (concourse+platform)\n",
        "# - Saves consolidated monthly CSV (+ optional per-day files)\n",
        "\n",
        "import os, csv, json, yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Paths & config\n",
        "ROOT = \"/content/2025_GP_28/masar-sim\"\n",
        "SEED = f\"{ROOT}/data/seeds\"\n",
        "CONF = f\"{ROOT}/sims/00_config.yaml\"\n",
        "OUT_DIR = f\"{ROOT}/data/generated\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "config = {}\n",
        "if os.path.exists(CONF):\n",
        "    with open(CONF, \"r\", encoding=\"utf-8\") as f:\n",
        "        config = yaml.safe_load(f) or {}\n",
        "\n",
        "# Month window (inclusive)\n",
        "MONTH = \"2025-09\"\n",
        "MONTH_START = pd.Timestamp(f\"{MONTH}-01\")\n",
        "MONTH_END   = pd.Timestamp(f\"{MONTH}-30\")  # 30 days in Sep\n",
        "\n",
        "HOLIDAYS_ON = False\n",
        "SAVE_DAILY  = False\n",
        "\n",
        "# 1- Load base-day template\n",
        "# We only need a single-day base grid: station_id, minute_of_day, base_demand\n",
        "candidates = [\n",
        "    f\"{OUT_DIR}/day_base.csv\",\n",
        "    f\"{OUT_DIR}/base_day.csv\",\n",
        "    f\"{ROOT}/data/base/day_base.csv\",\n",
        "    f\"{ROOT}/data/base/base_day.csv\",\n",
        "    f\"{OUT_DIR}/day_demand_base.csv\",\n",
        "    f\"{ROOT}/data/base/day_demand_base.csv\",\n",
        "]\n",
        "src = next((p for p in candidates if os.path.exists(p)), None)\n",
        "if src is None:\n",
        "    raise FileNotFoundError(\"No base-day CSV found. Expected one of:\\n\" + \"\\n\".join(candidates))\n",
        "\n",
        "base_day = pd.read_csv(src)\n",
        "print(\"Loaded base-day from:\", src)\n",
        "\n",
        "# Normalize headers\n",
        "base_day.columns = [str(c).strip().lower() for c in base_day.columns]\n",
        "rename_map = {\n",
        "    \"station\":\"station_id\",\"station code\":\"station_id\",\"station_code\":\"station_id\",\"sid\":\"station_id\",\n",
        "    \"base\":\"base_demand\",\"basedemand\":\"base_demand\",\"demand_base\":\"base_demand\",\n",
        "    \"base_day_demand\":\"base_demand\",\"base_day\":\"base_demand\",\n",
        "    \"minute\":\"minute_of_day\",\"min\":\"minute_of_day\",\"minuteofday\":\"minute_of_day\",\"minute-of-day\":\"minute_of_day\",\n",
        "}\n",
        "base_day = base_day.rename(columns=rename_map)\n",
        "\n",
        "# Build minute_of_day if missing\n",
        "if \"minute_of_day\" not in base_day.columns:\n",
        "    if {\"hour\",\"minute\"}.issubset(base_day.columns):\n",
        "        base_day[\"minute_of_day\"] = (\n",
        "            pd.to_numeric(base_day[\"hour\"], errors=\"coerce\").fillna(0).astype(int)*60 +\n",
        "            pd.to_numeric(base_day[\"minute\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "        )\n",
        "    elif \"time\" in base_day.columns:\n",
        "        t = pd.to_datetime(base_day[\"time\"], errors=\"coerce\")\n",
        "        base_day[\"minute_of_day\"] = (t.dt.hour*60 + t.dt.minute).astype(\"Int64\").fillna(0).astype(int)\n",
        "    elif \"timestamp\" in base_day.columns:\n",
        "        ts = pd.to_datetime(base_day[\"timestamp\"], errors=\"coerce\")\n",
        "        base_day[\"minute_of_day\"] = (ts.dt.hour*60 + ts.dt.minute).astype(\"Int64\").fillna(0).astype(int)\n",
        "    else:\n",
        "        base_day = base_day.reset_index().rename(columns={\"index\":\"minute_of_day\"})\n",
        "        base_day[\"minute_of_day\"] = base_day[\"minute_of_day\"].clip(0, 1439).astype(int)\n",
        "\n",
        "for c in [\"station_id\",\"base_demand\",\"minute_of_day\"]:\n",
        "    if c not in base_day.columns:\n",
        "        raise KeyError(f\"Missing required column '{c}' in base-day template.\")\n",
        "\n",
        "base_day[\"station_id\"]     = base_day[\"station_id\"].astype(str).str.strip()\n",
        "base_day[\"base_demand\"]    = pd.to_numeric(base_day[\"base_demand\"], errors=\"coerce\").fillna(0.0)  # 0..1 normalized\n",
        "base_day[\"minute_of_day\"]  = pd.to_numeric(base_day[\"minute_of_day\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# 2- Stations & capacities\n",
        "def _norm(x): return str(x).strip().upper()\n",
        "\n",
        "with open(f\"{SEED}/stations.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    stations_list = json.load(f)\n",
        "\n",
        "stations_df = pd.json_normalize(stations_list)\n",
        "\n",
        "# Fallbacks\n",
        "if \"capacity_station\" not in stations_df.columns:\n",
        "    stations_df[\"capacity_station\"] = 2000\n",
        "if \"capacity_platform\" not in stations_df.columns:\n",
        "    stations_df[\"capacity_platform\"] = 1500\n",
        "\n",
        "# Served lines count\n",
        "if \"served_lines\" in stations_df.columns:\n",
        "    served_counts = stations_df[\"served_lines\"].apply(lambda v: len(v) if isinstance(v, (list,tuple)) else 1)\n",
        "else:\n",
        "    served_counts = 1\n",
        "\n",
        "# Train total capacity\n",
        "if \"train_capacity.train_total\" in stations_df.columns:\n",
        "    train_total_cap = pd.to_numeric(stations_df[\"train_capacity.train_total\"], errors=\"coerce\").fillna(556)\n",
        "elif \"train_capacity\" in stations_df.columns:\n",
        "\n",
        "    def _cap(x):\n",
        "        try:\n",
        "            return float(x.get(\"train_total\", 556))\n",
        "        except Exception:\n",
        "            return 556.0\n",
        "    train_total_cap = stations_df[\"train_capacity\"].apply(_cap)\n",
        "else:\n",
        "    train_total_cap = 556.0\n",
        "\n",
        "stations_df[\"_served_lines_count\"] = served_counts.astype(int).clip(lower=1)\n",
        "stations_df[\"_train_total_cap\"]    = pd.to_numeric(train_total_cap, errors=\"coerce\").fillna(556.0)\n",
        "\n",
        "capacity_df = stations_df[[\n",
        "    \"station_id\",\"capacity_station\",\"capacity_platform\",\"_served_lines_count\",\"_train_total_cap\"\n",
        "]].copy()\n",
        "\n",
        "# Quick SID maps\n",
        "sid_by_code, sid_by_name = {}, {}\n",
        "for st in stations_list:\n",
        "    sid  = str(st.get(\"station_id\",\"\")).strip()\n",
        "    code = str(st.get(\"code\",\"\")).strip()\n",
        "    name = str(st.get(\"name\",\"\")).strip()\n",
        "    if code: sid_by_code[_norm(code)] = sid\n",
        "    if name: sid_by_name[_norm(name)] = sid\n",
        "\n",
        "ALIASES = {\n",
        "    \"AIRPORT T1-2\": \"AIRP_T12\",\n",
        "    \"QASR AL-HOKM\": \"QASR\",\n",
        "    \"NATIONAL MUSEUM\": \"MUSEUM\",\n",
        "    \"WESTERN STATION\": \"S6\",\n",
        "}\n",
        "def resolve_sid(token: str):\n",
        "    t = _norm(token)\n",
        "    if t in sid_by_code: return sid_by_code[t]\n",
        "    if t in sid_by_name: return sid_by_name[t]\n",
        "    if t in ALIASES:\n",
        "        c = _norm(ALIASES[t]); return sid_by_code.get(c, ALIASES[t])\n",
        "    return None\n",
        "\n",
        "# 3- Calendar (events & holidays)\n",
        "def norm_date(x: str) -> str:\n",
        "    if x is None: return \"\"\n",
        "    s = str(x).strip()\n",
        "    if not s: return \"\"\n",
        "    d = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
        "    if pd.isna(d):\n",
        "        d = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
        "    return \"\" if pd.isna(d) else d.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Events\n",
        "events_csv = f\"{SEED}/calendar_events.csv\"\n",
        "event_rows = []\n",
        "with open(events_csv, \"r\", encoding=\"utf-8\") as f:\n",
        "    rdr = csv.DictReader(f)\n",
        "    cols = {c.lower().strip(): c for c in rdr.fieldnames}\n",
        "    for r in rdr:\n",
        "        event_rows.append({\n",
        "            \"date\": norm_date(r.get(cols.get(\"date\",\"date\"), \"\")),\n",
        "            \"event_type\": (r.get(cols.get(\"event_type\",\"event_type\")) or r.get(cols.get(\"type\",\"type\")) or \"Other\").strip(),\n",
        "            \"stations_impacted\": (r.get(cols.get(\"stations_impacted\",\"stations_impacted\")) or r.get(cols.get(\"stations\",\"stations\")) or \"*\").strip(),\n",
        "            \"demand_modifier\": float((r.get(cols.get(\"demand_modifier\",\"demand_modifier\")) or \"1.0\")),\n",
        "        })\n",
        "\n",
        "GLOBAL_EVENT_TYPES = {\"SaudiNationalDay\"}\n",
        "event_types_map = {}              # (date, SID) -> set(types)\n",
        "event_mult_override = {}          # (date, SID) -> product(mods)\n",
        "global_event_types_by_date = {}   # date -> set(types)\n",
        "global_event_mult_by_date  = {}   # date -> product(mods)\n",
        "\n",
        "for e in event_rows:\n",
        "    d = e[\"date\"]\n",
        "    if not d: continue\n",
        "    etype = e[\"event_type\"] or \"Other\"\n",
        "    dm    = float(e.get(\"demand_modifier\", 1.0) or 1.0)\n",
        "    tokens = [s.strip() for s in (e[\"stations_impacted\"] or \"*\").split(\";\")]\n",
        "\n",
        "    is_global = (etype in GLOBAL_EVENT_TYPES) or any(_norm(t) in {\"*\",\"ALL\",\"ALL STATIONS\"} for t in tokens)\n",
        "    if is_global:\n",
        "        global_event_types_by_date.setdefault(d, set()).add(etype)\n",
        "        global_event_mult_by_date[d] = global_event_mult_by_date.get(d, 1.0) * dm\n",
        "\n",
        "    for tok in tokens:\n",
        "        if tok == \"\" or _norm(tok) in {\"*\",\"ALL\",\"ALL STATIONS\"}: continue\n",
        "        sid = resolve_sid(tok)\n",
        "        if sid is None:\n",
        "            print(f\"[warn] Unknown station alias in events CSV: '{tok}'\")\n",
        "            continue\n",
        "        key = (d, _norm(sid))\n",
        "        event_types_map.setdefault(key, set()).add(etype)\n",
        "        event_mult_override[key] = event_mult_override.get(key, 1.0) * dm\n",
        "\n",
        "def list_event_types(date_str, sid):\n",
        "    sidn = _norm(sid)\n",
        "    types = set()\n",
        "    if (date_str, sidn) in event_types_map:\n",
        "        types |= event_types_map[(date_str, sidn)]\n",
        "    if date_str in global_event_types_by_date:\n",
        "        types |= global_event_types_by_date[date_str]\n",
        "    return sorted(types)\n",
        "\n",
        "def event_csv_multiplier(date_str, sid):\n",
        "    sidn = _norm(sid)\n",
        "    m = 1.0\n",
        "    if (date_str, sidn) in event_mult_override:\n",
        "        m *= event_mult_override[(date_str, sidn)]\n",
        "    if date_str in global_event_mult_by_date:\n",
        "        m *= global_event_mult_by_date[date_str]\n",
        "    return float(m)\n",
        "\n",
        "# 4- Multipliers\n",
        "mult_cfg     = (config.get(\"multipliers\", {}) or {})\n",
        "weather_mult = mult_cfg.get(\"weather\", {}) or {}\n",
        "events_mult  = mult_cfg.get(\"events\", {}) or {}\n",
        "weekend_mult = float(mult_cfg.get(\"weekend\", 1.0))\n",
        "COMBINE_MODE = \"stack\"\n",
        "\n",
        "def build_modifier(row):\n",
        "    m = 1.0\n",
        "    # weekend\n",
        "    if int(row.get(\"is_weekend\",0)) == 1:\n",
        "        m *= weekend_mult\n",
        "\n",
        "    # holiday\n",
        "    hol_m = holiday_mult if row[\"date\"] in holiday_dates else 1.0\n",
        "\n",
        "    # events\n",
        "    ev_m = event_csv_multiplier(row[\"date\"], row[\"station_id\"])\n",
        "    if ev_m == 1.0:\n",
        "        tmp = 1.0\n",
        "        for t in list_event_types(row[\"date\"], row[\"station_id\"]):\n",
        "            tmp *= float(events_mult.get(t, events_mult.get(\"Other\", 1.0)))\n",
        "        ev_m = tmp if tmp != 1.0 else 1.0\n",
        "\n",
        "    m = m * hol_m * ev_m if COMBINE_MODE == \"stack\" else m * max(hol_m, ev_m)\n",
        "\n",
        "    # weather\n",
        "    w = str(row.get(\"weather_code\", \"\") or \"\")\n",
        "    m *= float(weather_mult.get(w, 1.0))\n",
        "    return float(m)\n",
        "\n",
        "# 5- Build the full month grid\n",
        "dates = pd.date_range(MONTH_START, MONTH_END, freq=\"D\")\n",
        "frames = []\n",
        "for d in dates:\n",
        "    df_d = base_day.copy()\n",
        "    h = (df_d[\"minute_of_day\"] // 60).astype(int)\n",
        "    m = (df_d[\"minute_of_day\"] %  60).astype(int)\n",
        "    date_iso = d.strftime(\"%Y-%m-%d\")\n",
        "    df_d[\"date\"]        = date_iso\n",
        "    df_d[\"timestamp\"]   = pd.to_datetime(f\"{date_iso} \" + h.astype(str).str.zfill(2) + \":\" + m.astype(str).str.zfill(2) + \":00\")\n",
        "    df_d[\"hour\"]        = h\n",
        "    df_d[\"day_of_week\"] = d.weekday()\n",
        "    df_d[\"is_weekend\"]  = df_d[\"day_of_week\"].isin([4,5]).astype(int)  # Fri=4, Sat=5\n",
        "    frames.append(df_d)\n",
        "\n",
        "df = pd.concat(frames, ignore_index=True).sort_values([\"date\",\"station_id\",\"minute_of_day\"]).reset_index(drop=True)\n",
        "\n",
        "# 6- Apply modifiers\n",
        "df[\"modifier\"] = df.apply(build_modifier, axis=1)\n",
        "base_demand_norm = pd.to_numeric(df.get(\"base_demand\", 0), errors=\"coerce\").fillna(0.0)  # 0..1\n",
        "df[\"demand_final\"] = (base_demand_norm * pd.to_numeric(df[\"modifier\"], errors=\"coerce\").fillna(1.0)).fillna(0.0)\n",
        "\n",
        "#  7- Merge capacities, lines, train cap\n",
        "df = df.merge(capacity_df, on=\"station_id\", how=\"left\")\n",
        "\n",
        "# Effective directions\n",
        "dirs = (2 * pd.to_numeric(df[\"_served_lines_count\"], errors=\"coerce\").fillna(1).clip(lower=1)).astype(float)\n",
        "df[\"_effective_dirs\"] = dirs\n",
        "\n",
        "# Train total capacity per train\n",
        "df[\"_train_total_cap\"] = pd.to_numeric(df[\"_train_total_cap\"], errors=\"coerce\").fillna(556.0)\n",
        "\n",
        "# 8- Headway (sec) from config\n",
        "headway_cfg = config.get(\"headway\", {})\n",
        "peaks_cfg   = config.get(\"peaks\", [])\n",
        "peak_hours  = [int(x.get(\"hour\")) for x in peaks_cfg if \"hour\" in x] or [7,8,17,18]\n",
        "\n",
        "peak_hw_min    = float(np.median(headway_cfg.get(\"peak_pattern\",    [7,7,6,8])))\n",
        "offpeak_hw_min = float(np.median(headway_cfg.get(\"offpeak_pattern\", [11,10,12,11])))\n",
        "\n",
        "def hw_for_hour(h):\n",
        "    return int(peak_hw_min*60) if int(h) in peak_hours else int(offpeak_hw_min*60)\n",
        "\n",
        "df[\"headway_seconds\"] = pd.to_numeric(df.get(\"headway_seconds\"), errors=\"coerce\")\n",
        "mask = df[\"headway_seconds\"].isna()\n",
        "df.loc[mask, \"headway_seconds\"] = df.loc[mask, \"hour\"].apply(hw_for_hour)\n",
        "df[\"headway_seconds\"] = df[\"headway_seconds\"].astype(int)\n",
        "\n",
        "\n",
        "# 9- Revised Occupancy / Crowd Model (key tunables here)\n",
        "\n",
        "# Tunable knobs\n",
        "TARGET_UTIL          = 0.85   # peak utilization of service capacity per station\n",
        "LOAD_FACTOR          = 0.65   # train load factor\n",
        "CONCOURSE_DWELL_MIN  = 6.0    # avg mins in concourse\n",
        "PLATFORM_DWELL_FLOOR = 2.0    # min minutes on platform\n",
        "QUEUE_SENS           = 0.60   # sensitivity of queueing to worse-than-peak headway\n",
        "EVENT_BUMP           = 0.80   # how much event multiplier\n",
        "EVENT_BUMP_MAX       = 0.50   # cap for event bump\n",
        "CAP_BOOST_EVENT      = 1.25   # allow up to +25% above capacity during events\n",
        "\n",
        "# Service capacity at peak\n",
        "PEAK_HW_MIN = max(peak_hw_min, 1e-6)\n",
        "df[\"_mu_peak\"] = (df[\"_effective_dirs\"] / PEAK_HW_MIN) * df[\"_train_total_cap\"] * LOAD_FACTOR\n",
        "\n",
        "# Daily shape from normalized curve\n",
        "df[\"_day_max\"] = df.groupby([\"station_id\",\"date\"])[\"demand_final\"].transform(\"max\").replace(0, np.nan)\n",
        "df[\"_shape\"]   = (df[\"demand_final\"] / df[\"_day_max\"]).fillna(0.0).clip(0, 1)\n",
        "\n",
        "# Arrivals\n",
        "df[\"station_flow_per_min\"] = df[\"_shape\"] * df[\"_mu_peak\"] * TARGET_UTIL\n",
        "\n",
        "# Platform occupants\n",
        "df[\"_wait_min\"] = (df[\"headway_seconds\"].astype(float) / 120.0).clip(lower=PLATFORM_DWELL_FLOOR)\n",
        "df[\"_occ_platform\"] = df[\"station_flow_per_min\"] * df[\"_wait_min\"]\n",
        "df[\"_occ_concourse\"] = df[\"station_flow_per_min\"] * CONCOURSE_DWELL_MIN\n",
        "\n",
        "# Queue bump for worse-than-peak headways\n",
        "peak_hw_sec = PEAK_HW_MIN * 60.0\n",
        "df[\"_hw_blowup\"] = ((df[\"headway_seconds\"] - peak_hw_sec) / max(peak_hw_sec, 1.0)).clip(lower=0.0)\n",
        "df[\"_queue_bump_factor\"] = (1.0 + QUEUE_SENS * df[\"_hw_blowup\"])\n",
        "\n",
        "# Event bump (limited)\n",
        "ev_mult = df.apply(lambda r: event_csv_multiplier(r[\"date\"], r[\"station_id\"]), axis=1)\n",
        "df[\"_event_bump_factor\"] = 1.0 + np.minimum(EVENT_BUMP_MAX, EVENT_BUMP * np.maximum(0.0, ev_mult - 1.0))\n",
        "\n",
        "# Total occupancy before capping\n",
        "df[\"_occ_base\"]  = df[\"_occ_concourse\"] + df[\"_occ_platform\"]\n",
        "df[\"_occ_total\"] = df[\"_occ_base\"] * df[\"_queue_bump_factor\"] * df[\"_event_bump_factor\"]\n",
        "\n",
        "# Cap occupancy by capacity (+ boost on events)\n",
        "cap_station = pd.to_numeric(df[\"capacity_station\"], errors=\"coerce\").fillna(0.0)\n",
        "is_event = (df.apply(lambda r: len(list_event_types(r[\"date\"], r[\"station_id\"])) > 0, axis=1)).astype(int)\n",
        "df[\"_cap_boost\"] = np.where(is_event == 1, CAP_BOOST_EVENT, 1.0)\n",
        "\n",
        "df[\"station_total\"] = np.minimum(df[\"_occ_total\"], cap_station * df[\"_cap_boost\"]).round().astype(int).clip(lower=0)\n",
        "\n",
        "def crowd_from_cap(row):\n",
        "    cap = float(row.get(\"capacity_station\") or 0)\n",
        "    x = float(row.get(\"station_total\") or 0)\n",
        "    if cap <= 0: return \"Medium\"\n",
        "    r = x / cap\n",
        "    if   r < 0.30: return \"Low\"\n",
        "    elif r < 0.60: return \"Medium\"\n",
        "    elif r < 0.85: return \"High\"\n",
        "    else:          return \"Extreme\"\n",
        "df[\"crowd_level\"] = df.apply(crowd_from_cap, axis=1)\n",
        "\n",
        "# flags / types, read from calendar CSV\n",
        "df[\"special_event_type\"] = df.apply(lambda r: \"+\".join(list_event_types(r[\"date\"], r[\"station_id\"])) or \"None\", axis=1)\n",
        "df[\"event_flag\"]   = (df[\"special_event_type\"] != \"None\").astype(int)\n",
        "df[\"holiday_flag\"] = df[\"date\"].isin(holiday_dates).astype(int) if HOLIDAYS_ON else 0\n",
        "\n",
        "# 10- Output, monthly + optional daily\n",
        "FINAL_SCHEMA = [\n",
        "    \"date\",\"timestamp\",\"hour\",\"minute_of_day\",\"day_of_week\",\"is_weekend\",\n",
        "    \"station_id\",\n",
        "    \"base_demand\",\"modifier\",\"demand_final\",\n",
        "    \"station_flow_per_min\",\n",
        "    \"station_total\",\"crowd_level\",\n",
        "    \"special_event_type\",\"event_flag\",\"holiday_flag\",\n",
        "    \"headway_seconds\"\n",
        "]\n",
        "\n",
        "for c in FINAL_SCHEMA:\n",
        "    if c not in df.columns:\n",
        "        df[c] = np.nan\n",
        "\n",
        "out = df[FINAL_SCHEMA].sort_values([\"date\",\"station_id\",\"minute_of_day\"]).reset_index(drop=True)\n",
        "\n",
        "# QA\n",
        "assert out[\"station_id\"].notna().all()\n",
        "assert (out[\"station_total\"] >= 0).all()\n",
        "\n",
        "# Save monthly file\n",
        "OUT_MONTH = f\"{OUT_DIR}/cf_month_{MONTH}.csv\"\n",
        "out.to_csv(OUT_MONTH, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"Saved âœ“\", OUT_MONTH, \"| Rows:\", len(out), \"| Dates:\", out['date'].min(), \"â†’\", out['date'].max())\n",
        "\n",
        "# Optional, per-day files\n",
        "if SAVE_DAILY:\n",
        "    for d, g in out.groupby(\"date\", sort=True):\n",
        "        p = f\"{OUT_DIR}/cf_day_{d}.csv\"\n",
        "        g.to_csv(p, index=False, encoding=\"utf-8-sig\")\n",
        "    print(\"Daily CSVs saved in:\", OUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzYe2d0Tpw6E",
        "outputId": "bfa85bf6-118f-46d5-b533-23c38c912131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded base-day from: /content/2025_GP_28/masar-sim/data/generated/base_day.csv\n",
            "Saved âœ“ /content/2025_GP_28/masar-sim/data/generated/cf_month_2025-09.csv | Rows: 194580 | Dates: 2025-09-01 â†’ 2025-09-30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(f\"{OUT_DIR}/cf_month_2025-09.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wVo8hBcVLzJ_",
        "outputId": "5c226032-1c12-4a0c-d6ab-56ea7a9fe2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c63f986f-1f01-4cdf-b2ea-20e1e19e8fb3\", \"cf_month_2025-09.csv\", 23604160)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}