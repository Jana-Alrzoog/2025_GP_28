{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKRocKz0u2z/EH7KJ8r2B9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jana-Alrzoog/2025_GP_28/blob/main/masar-sim/notebooks/masar_occupancy_day.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# üöá Masar Occupancy ‚Äî Day Generator\n",
        "\n",
        "This notebook generates **minute-level passenger occupancy** for a single day across selected stations/lines.\n",
        "It applies the **base-day curve** and multiplies it by **context modifiers** (station capacity, weekend, weather, and events ‚Äî holidays disabled per current config), then exports tidy CSVs ready for weekly/monthly aggregation and dashboards.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Purpose\n",
        "\n",
        "* Produce **24-hour occupancy time series** at 1-minute resolution.\n",
        "* Apply standardized modifiers to reflect realistic day-to-day variation.\n",
        "* Emit clean outputs for QA, visualization, and Firestore/pipeline publishing.\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Inputs\n",
        "\n",
        "* **`base_day.csv`** (from `masar_base_demand.ipynb`)\n",
        "* **Seeds:** `stations`, `events`, `weather` (holidays ignored)\n",
        "* **Config:** `00_config.yaml` (paths, multipliers, timezone, resolution)\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Workflow\n",
        "\n",
        "1Ô∏è‚É£ **Load config & seeds** (paths, stations, events, weather).\n",
        "2Ô∏è‚É£ **Pick target date** (e.g., `DATE=\"2025-09-23\"`), set `TZ` and `MINUTE_RES`.\n",
        "3Ô∏è‚É£ **Build minute grid** for the day per station.\n",
        "4Ô∏è‚É£ **Compute modifiers** per minute:\n",
        "\n",
        "* `station_scale` (capacity vs. network mean)\n",
        "* `weekend_mult` (Fri/Sat)\n",
        "* `weather_mult` (Sunny/Dusty/Rainy‚Ä¶)\n",
        "* `event_mult` (supports `stations_impacted` lists)\n",
        "* *(holiday multiplier disabled by design)*\n",
        "  5Ô∏è‚É£ **Apply**: `occupancy = base_norm √ó final_modifier`.\n",
        "  6Ô∏è‚É£ **Export CSVs** and basic charts.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "3BT3Mt8Py3E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Jana-Alrzoog/2025_GP_28.git\n",
        "%cd /content/2025_GP_28/masar-sim\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKmRIaQb6_Pc",
        "outputId": "c33c9fe8-6ed3-4657-9a4e-e35b943639b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '2025_GP_28'...\n",
            "remote: Enumerating objects: 662, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (170/170), done.\u001b[K\n",
            "remote: Total 662 (delta 92), reused 1 (delta 1), pack-reused 485 (from 1)\u001b[K\n",
            "Receiving objects: 100% (662/662), 4.57 MiB | 9.11 MiB/s, done.\n",
            "Resolving deltas: 100% (239/239), done.\n",
            "/content/2025_GP_28/masar-sim\n",
            "data  lib  notebooks  sims\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = \"/content/2025_GP_28/masar-sim\"\n",
        "GEN = f\"{ROOT}/data/generated\"\n",
        "SEED = f\"{ROOT}/data/seeds\"\n",
        "CONF = f\"{ROOT}/sims/00_config.yaml\"\n"
      ],
      "metadata": {
        "id": "2GgdKafv7DNH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/2025_GP_28\n",
        "!git fetch origin\n",
        "!git checkout main\n",
        "!git reset --hard origin/main\n",
        "!ls masar-sim/sims\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJKQI-7e8srg",
        "outputId": "9572aa72-79b7-40d4-8ec7-cce51ed8b685"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/2025_GP_28\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "HEAD is now at d2ec5b3 Created using Colab\n",
            "00_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/Jana-Alrzoog/2025_GP_28.git 2025_GP_28_latest\n",
        "!ls /content/2025_GP_28_latest/masar-sim/sims\n",
        "\n",
        "ROOT = \"/content/2025_GP_28_latest/masar-sim\"\n",
        "GEN  = f\"{ROOT}/data/generated\"\n",
        "SEED = f\"{ROOT}/data/seeds\"\n",
        "CONF = f\"{ROOT}/sims/00_config.yaml\"\n",
        "\n",
        "!mkdir -p $GEN\n",
        "!cp /content/2025_GP_28/masar-sim/data/generated/base_demand_day.csv $GEN/\n",
        "\n",
        "!ls $CONF\n",
        "!ls $GEN\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdJLky_u9925",
        "outputId": "38c50a9a-98e4-46a4-a889-f1968ae6c0e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path '2025_GP_28_latest' already exists and is not an empty directory.\n",
            "00_config.yaml\n",
            "/content/2025_GP_28_latest/masar-sim/sims/00_config.yaml\n",
            "base_day.csv\t     cf_week_f.csv\toccupancy_week.csv\n",
            "base_demand_day.csv  occupancy_day.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, csv, yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = \"/content/2025_GP_28_latest/masar-sim\"\n",
        "GEN  = f\"{ROOT}/data/generated\"\n",
        "SEED = f\"{ROOT}/data/seeds\"\n",
        "CONF = f\"{ROOT}/sims/00_config.yaml\"\n",
        "\n",
        "base_path = f\"{GEN}/base_day.csv\"\n",
        "assert os.path.exists(base_path), \"base_day.csv not found\"\n",
        "\n",
        "base_df = pd.read_csv(base_path, parse_dates=[\"timestamp\"])\n",
        "\n",
        "with open(CONF) as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "with open(f\"{SEED}/stations.json\") as f:\n",
        "    stations = json.load(f)\n",
        "with open(f\"{SEED}/weather_patterns.json\") as f:\n",
        "    weather_map = json.load(f)\n",
        "with open(f\"{SEED}/calendar_events.csv\") as f:\n",
        "    events = list(csv.DictReader(f))\n",
        "\n",
        "print(\"rows:\", len(base_df), \"| stations:\", base_df[\"station_id\"].nunique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdWa9Trj-3qC",
        "outputId": "05f271de-25cc-4c43-8c24-8e6f5654f332"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rows: 6486 | stations: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, csv, json, yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ===================== 0) Data sources =====================\n",
        "# Expect one of these to exist in memory: week_df or base_df\n",
        "if 'week_df' in globals():\n",
        "    df = week_df.copy()\n",
        "elif 'base_df' in globals():\n",
        "    df = base_df.copy()\n",
        "else:\n",
        "    raise RuntimeError(\"week_df or base_df not found in memory.\")\n",
        "\n",
        "# Root paths\n",
        "if 'ROOT' not in globals():\n",
        "    ROOT = \"/content/2025_GP_28/masar-sim\"\n",
        "SEED = f\"{ROOT}/data/seeds\"\n",
        "CONF = f\"{ROOT}/sims/00_config.yaml\"\n",
        "\n",
        "# Config\n",
        "with open(CONF, \"r\", encoding=\"utf-8\") as f:\n",
        "    config = yaml.safe_load(f) or {}\n",
        "\n",
        "# ===================== 1) Time fields + single-day window =====================\n",
        "ts = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "df[\"timestamp\"]     = ts\n",
        "df[\"date\"]          = ts.dt.strftime(\"%Y-%m-%d\")\n",
        "df[\"hour\"]          = ts.dt.hour\n",
        "df[\"minute_of_day\"] = df[\"hour\"]*60 + ts.dt.minute\n",
        "df[\"day_of_week\"]   = ts.dt.weekday\n",
        "if \"is_weekend\" not in df.columns:\n",
        "    # Fri=4, Sat=5 in Asia/Riyadh\n",
        "    df[\"is_weekend\"] = df[\"day_of_week\"].isin([4,5]).astype(int)\n",
        "\n",
        "# Pick ONE day (default: 2025-09-24).\n",
        "# Tip: if you previously used 'day_demand_base.csv', rename to 'day_base.csv' in your pipeline.\n",
        "DAY_DATE = pd.Timestamp(\"2025-09-24\")\n",
        "mask_day = (df[\"timestamp\"] >= DAY_DATE) & (df[\"timestamp\"] < DAY_DATE + pd.Timedelta(days=1))\n",
        "df = df.loc[mask_day].copy()\n",
        "if df.empty:\n",
        "    raise RuntimeError(f\"No rows found for the day window: {DAY_DATE.date()}\")\n",
        "\n",
        "# ===================== 2) Station mapping =====================\n",
        "def _norm(x): return str(x).strip().upper()\n",
        "\n",
        "with open(f\"{SEED}/stations.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    stations_list = json.load(f)\n",
        "\n",
        "sid_by_code, sid_by_name = {}, {}\n",
        "for st in stations_list:\n",
        "    sid  = str(st.get(\"station_id\",\"\")).strip()\n",
        "    code = str(st.get(\"code\",\"\")).strip()\n",
        "    name = str(st.get(\"name\",\"\")).strip()\n",
        "    if code: sid_by_code[_norm(code)] = sid\n",
        "    if name: sid_by_name[_norm(name)] = sid\n",
        "\n",
        "capacity_df = pd.DataFrame(stations_list)[[\"station_id\",\"capacity_station\"]]\n",
        "\n",
        "ALIASES = {\n",
        "    \"AIRPORT T1-2\": \"AIRP_T12\",\n",
        "    \"QASR AL-HOKM\": \"QASR\",\n",
        "    \"NATIONAL MUSEUM\": \"MUSEUM\",\n",
        "    \"WESTERN STATION\": \"S6\",\n",
        "}\n",
        "def resolve_sid(token: str):\n",
        "    t = _norm(token)\n",
        "    if t in sid_by_code: return sid_by_code[t]\n",
        "    if t in sid_by_name: return sid_by_name[t]\n",
        "    if t in ALIASES:\n",
        "        c = _norm(ALIASES[t])\n",
        "        return sid_by_code.get(c, ALIASES[t])\n",
        "    return None\n",
        "\n",
        "# ===================== 3) Events only (holidays disabled) =====================\n",
        "def norm_date(x: str) -> str:\n",
        "    if x is None: return \"\"\n",
        "    s = str(x).strip()\n",
        "    if not s: return \"\"\n",
        "    d = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
        "    if pd.isna(d):\n",
        "        d = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
        "    return \"\" if pd.isna(d) else d.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "events_csv = f\"{SEED}/calendar_events.csv\"\n",
        "event_rows = []\n",
        "with open(events_csv, \"r\", encoding=\"utf-8\") as f:\n",
        "    rdr = csv.DictReader(f)\n",
        "    cols = {c.lower().strip(): c for c in rdr.fieldnames}\n",
        "    for r in rdr:\n",
        "        event_rows.append({\n",
        "            \"date\": norm_date(r.get(cols.get(\"date\",\"date\"), \"\")),\n",
        "            \"event_type\": (r.get(cols.get(\"event_type\",\"event_type\")) or r.get(cols.get(\"type\",\"type\")) or \"Other\").strip(),\n",
        "            \"stations_impacted\": (r.get(cols.get(\"stations_impacted\",\"stations_impacted\")) or r.get(cols.get(\"stations\",\"stations\")) or \"*\").strip(),\n",
        "            \"demand_modifier\": float((r.get(cols.get(\"demand_modifier\",\"demand_modifier\")) or \"1.0\")),\n",
        "        })\n",
        "\n",
        "# Global events (e.g., SaudiNationalDay) still supported, but holidays are disabled below.\n",
        "GLOBAL_EVENT_TYPES = {\"SaudiNationalDay\"}\n",
        "\n",
        "event_types_map = {}              # (date, SID) -> set(types)\n",
        "event_mult_override = {}          # (date, SID) -> product(mods)\n",
        "global_event_types_by_date = {}   # date -> set(types)\n",
        "global_event_mult_by_date  = {}   # date -> product(mods)\n",
        "\n",
        "for e in event_rows:\n",
        "    d = e[\"date\"]\n",
        "    if not d:\n",
        "        continue\n",
        "    etype = e[\"event_type\"] or \"Other\"\n",
        "    dm    = float(e.get(\"demand_modifier\", 1.0) or 1.0)\n",
        "    tokens = [s.strip() for s in (e[\"stations_impacted\"] or \"*\").split(\";\")]\n",
        "\n",
        "    # Global event?\n",
        "    is_global = (etype in GLOBAL_EVENT_TYPES) or any(_norm(t) in {\"*\", \"ALL\", \"ALL STATIONS\"} for t in tokens)\n",
        "    if is_global:\n",
        "        global_event_types_by_date.setdefault(d, set()).add(etype)\n",
        "        global_event_mult_by_date[d] = global_event_mult_by_date.get(d, 1.0) * dm\n",
        "\n",
        "    # Station-specific events\n",
        "    for tok in tokens:\n",
        "        if tok == \"\" or _norm(tok) in {\"*\", \"ALL\", \"ALL STATIONS\"}:\n",
        "            continue\n",
        "        sid = resolve_sid(tok)\n",
        "        if sid is None:\n",
        "            print(f\"[warn] Unknown station alias in events CSV: '{tok}'\")\n",
        "            continue\n",
        "        key = (d, _norm(sid))\n",
        "        event_types_map.setdefault(key, set()).add(etype)\n",
        "        event_mult_override[key] = event_mult_override.get(key, 1.0) * dm\n",
        "\n",
        "# Holidays DISABLED (force empty set)\n",
        "holiday_dates = set()\n",
        "\n",
        "def list_event_types(date_str, sid):\n",
        "    sidn = _norm(sid)\n",
        "    types = set()\n",
        "    if (date_str, sidn) in event_types_map:\n",
        "        types |= event_types_map[(date_str, sidn)]\n",
        "    if date_str in global_event_types_by_date:\n",
        "        types |= global_event_types_by_date[date_str]\n",
        "    return sorted(types)\n",
        "\n",
        "def event_csv_multiplier(date_str, sid):\n",
        "    sidn = _norm(sid)\n",
        "    m = 1.0\n",
        "    if (date_str, sidn) in event_mult_override:\n",
        "        m *= event_mult_override[(date_str, sidn)]\n",
        "    if date_str in global_event_mult_by_date:\n",
        "        m *= global_event_mult_by_date[date_str]\n",
        "    return float(m)\n",
        "\n",
        "# ===================== 4) Multipliers (weekend + events + weather); holidays off =====================\n",
        "mult_cfg     = (config.get(\"multipliers\", {}) or {})\n",
        "weather_mult = mult_cfg.get(\"weather\", {}) or {}\n",
        "events_mult  = mult_cfg.get(\"events\", {}) or {}\n",
        "weekend_mult = float(mult_cfg.get(\"weekend\", 1.0))\n",
        "holiday_mult = 1.0  # force no holiday effect\n",
        "COMBINE_MODE = \"stack\"  # \"stack\" => multiply; else use max(holiday, events)\n",
        "\n",
        "def build_modifier(row):\n",
        "    m = 1.0\n",
        "    # weekend\n",
        "    if int(row.get(\"is_weekend\",0)) == 1:\n",
        "        m *= weekend_mult\n",
        "\n",
        "    # holidays disabled => hol_m = 1.0 always\n",
        "    hol_m = 1.0\n",
        "\n",
        "    # events: prefer explicit CSV multiplier; otherwise fallback to config-based types\n",
        "    ev_m = event_csv_multiplier(row[\"date\"], row[\"station_id\"])\n",
        "    if ev_m == 1.0:\n",
        "        tmp = 1.0\n",
        "        for t in list_event_types(row[\"date\"], row[\"station_id\"]):\n",
        "            tmp *= float(events_mult.get(t, events_mult.get(\"Other\", 1.0)))\n",
        "        ev_m = tmp if tmp != 1.0 else 1.0\n",
        "\n",
        "    m = m * hol_m * ev_m if COMBINE_MODE == \"stack\" else m * max(hol_m, ev_m)\n",
        "\n",
        "    # weather\n",
        "    w = str(row.get(\"weather_code\", \"\") or \"\")\n",
        "    m *= float(weather_mult.get(w, 1.0))\n",
        "    return float(m)\n",
        "\n",
        "df[\"modifier\"] = df.apply(build_modifier, axis=1)\n",
        "\n",
        "# ===================== 5) Final demand =====================\n",
        "base_demand_safe = pd.to_numeric(df.get(\"base_demand\", 0), errors=\"coerce\").fillna(0)\n",
        "df[\"demand_final\"] = (base_demand_safe * pd.to_numeric(df[\"modifier\"], errors=\"coerce\").fillna(1.0)).fillna(0)\n",
        "\n",
        "# ===================== 6) station_total + crowd_level =====================\n",
        "df = df.merge(capacity_df, on=\"station_id\", how=\"left\")\n",
        "df[\"_denom\"] = df.groupby(\"station_id\")[\"demand_final\"].transform(lambda s: max(s.max(), 1e-9))\n",
        "df[\"demand_norm_final\"] = (df[\"demand_final\"] / df[\"_denom\"]).clip(0, 1)\n",
        "\n",
        "def station_total_from_norm(row):\n",
        "    cap = float(row.get(\"capacity_station\") or 0)\n",
        "    if cap <= 0: return 0\n",
        "    norm = float(row[\"demand_norm_final\"])\n",
        "    evb  = event_csv_multiplier(row[\"date\"], row[\"station_id\"])\n",
        "    # Soft cap boost for events up to +10%\n",
        "    boost = min(1.10, 1.0 if evb <= 1.0 else min(evb, 1.10))\n",
        "    return int(np.round(norm * cap * boost))\n",
        "\n",
        "df[\"station_total\"] = df.apply(station_total_from_norm, axis=1).astype(int)\n",
        "\n",
        "def crowd_from_cap(row):\n",
        "    cap = float(row.get(\"capacity_station\") or 0)\n",
        "    x = float(row.get(\"station_total\") or 0)\n",
        "    if cap <= 0: return \"Medium\"\n",
        "    r = x / cap\n",
        "    if   r < 0.30: return \"Low\"\n",
        "    elif r < 0.60: return \"Medium\"\n",
        "    elif r < 0.85: return \"High\"\n",
        "    else:          return \"Extreme\"\n",
        "\n",
        "df[\"crowd_level\"] = df.apply(crowd_from_cap, axis=1)\n",
        "\n",
        "# ===================== 7) Event/holiday flags =====================\n",
        "df[\"special_event_type\"] = df.apply(lambda r: \"+\".join(list_event_types(r[\"date\"], r[\"station_id\"])) or \"None\", axis=1)\n",
        "df[\"event_flag\"]   = (df[\"special_event_type\"] != \"None\").astype(int)\n",
        "df[\"holiday_flag\"] = 0  # holidays disabled\n",
        "\n",
        "# ===================== 8) Headway seconds =====================\n",
        "headway_cfg = config.get(\"headway\", {})\n",
        "peaks_cfg   = config.get(\"peaks\", [])\n",
        "peak_hours  = [int(x.get(\"hour\")) for x in peaks_cfg if \"hour\" in x]\n",
        "peak_hw_min    = float(np.median(headway_cfg.get(\"peak_pattern\",    [7,7,6,8])))\n",
        "offpeak_hw_min = float(np.median(headway_cfg.get(\"offpeak_pattern\", [11,10,12,11])))\n",
        "def hw_for_hour(h): return int(peak_hw_min*60) if int(h) in peak_hours else int(offpeak_hw_min*60)\n",
        "\n",
        "if \"headway_seconds\" in df.columns:\n",
        "    df[\"headway_seconds\"] = pd.to_numeric(df[\"headway_seconds\"], errors=\"coerce\")\n",
        "    mask = df[\"headway_seconds\"].isna()\n",
        "    df.loc[mask, \"headway_seconds\"] = df.loc[mask, \"hour\"].apply(hw_for_hour)\n",
        "else:\n",
        "    df[\"headway_seconds\"] = df[\"hour\"].apply(hw_for_hour)\n",
        "df[\"headway_seconds\"] = df[\"headway_seconds\"].astype(int)\n",
        "\n",
        "# ===================== 9) Output (single day) =====================\n",
        "FINAL_SCHEMA = [\n",
        "    \"date\",\"timestamp\",\"hour\",\"minute_of_day\",\"day_of_week\",\"is_weekend\",\n",
        "    \"station_id\",\n",
        "    \"base_demand\",\"modifier\",\"demand_final\",\n",
        "    \"station_total\",\"crowd_level\",\n",
        "    \"special_event_type\",\"event_flag\",\"holiday_flag\",\n",
        "    \"headway_seconds\"\n",
        "]\n",
        "for c in FINAL_SCHEMA:\n",
        "    if c not in df.columns:\n",
        "        df[c] = np.nan\n",
        "\n",
        "out = df[FINAL_SCHEMA].sort_values([\"date\",\"station_id\",\"minute_of_day\"]).reset_index(drop=True)\n",
        "\n",
        "# QA\n",
        "assert out[\"station_id\"].notna().all()\n",
        "assert (out[\"station_total\"] >= 0).all()\n",
        "\n",
        "# Quick checks\n",
        "print(\"Rows for the selected day:\", len(out))\n",
        "print(\"Unique stations with event_flag=1:\", out[out[\"event_flag\"]==1][\"station_id\"].nunique())\n",
        "\n",
        "# Save as a per-day file (changed from 'cf_week_2025-09-21_to_27.csv')\n",
        "OUT_DIR = f\"{ROOT}/data/generated\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "OUT_PATH = f\"{OUT_DIR}/cf_day_{DAY_DATE.date()}.csv\"\n",
        "out.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"Saved ‚úì\", OUT_PATH)\n"
      ],
      "metadata": {
        "id": "U1YPnpTtAJPa",
        "outputId": "e4ae9f47-60ed-4136-c50c-843078a009fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows for the selected day: 6480\n",
            "Unique stations with event_flag=1: 0\n",
            "Saved ‚úì /content/2025_GP_28_latest/masar-sim/data/generated/cf_day_2025-09-24.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "OUT_PATH = f\"{ROOT}/data/generated/cf_day_{DAY_DATE.date()}.csv\"\n",
        "\n",
        "files.download(OUT_PATH)"
      ],
      "metadata": {
        "id": "XBq8pvN8AcRz",
        "outputId": "e2452252-bf4e-4e2e-b4c9-22605e21149a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0569a15e-04bf-4ea6-8a00-d50acee11d89\", \"cf_day_2025-09-24.csv\", 665925)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}